* pipeline in/out/err -- accept paths, open them as files, use the resulting file-ports for pipeline, then close the ports after the pipeline completes.  Should the files be appended or truncated?  Maybe append is a safer default option, and if you want truncate you use open-output-file explicitly.  However, a nice feature of having it wrappen in the pipeline library itself is automatic file-port closing -- you don't have to hang on to a reference of the port to close manually.  Maybe #:out etc could take a list that includes a path and 'truncate or 'append?
* probably strings given for in/out/err should be converted to paths -- a string for input could be used with open-input-string... maybe an #:in-string would be an alternate option.
* probably a 'null flag (or similar) could be passed for in/out/err to create a null pipe for output or an empty input pipe.

* kw-args for functions in shell pipelines
* a custom exn type for pipeline failures
* Pipeline suspend/resume -- Threads have pause/resume, Unix processes have sigstop/sigcont, but I'm not sure how to pause/suspend windows processes.  Maybe a Unix-only feature?

* path expansion functions -- ~, globs, /paths/with/$VARS/in/middle
* easy port opening functions for redirection to files (>, >>, <) and temp-file redirects ( <() )
* wrapper struct for functions to return non-zero but have it still count as success
* bg pipeline disowning?
    Disowning will probably only work for pipelines
    without any racket functions or filters in them.  But perhaps you should
    be able to mark a pipeline as disownable, which would start a new racket
    process which would run the pipeline?  It would have to be very restricted,
    because a pipeline could be using closures, which could not really be copied.
    It looks like bash and zsh can disown a backgrounded shell
    function and have it survive the shell exiting if that function was started
    in the background, which tells me that backgrounded bash/zsh functions are
    run in a subshell.  Presumably this means the process is forked, so that
    the subshell can still access all previously defined functions.  I feel
    like this could have many cases of subtle weirdness, so I'm not sure I
    want to follow that direction without something more explicit marking a
    clear boundary.  Also, fork() only works on Unix, and it would be nice if
    the shell worked on Windows too, so if I can reasonably avoid relying on
    fork, I should.

